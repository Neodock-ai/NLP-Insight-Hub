import streamlit as st
import logging
import os
from pathlib import Path
import importlib.util
import time
import re

# First check if dependencies are installed
try:
    from pipeline import data_ingestion, pre_processing, inference, post_processing
    from utils.logger import get_logger
    from utils.visualizations import create_sentiment_chart, create_keyword_cloud
except ImportError:
    st.error("Required modules not found. Installing dependencies...")
    import subprocess
    try:
        # Only run setup.sh if it exists
        if Path("setup.sh").exists():
            subprocess.run(["bash", "setup.sh"], check=True)
            st.success("Dependencies installed successfully! Please restart the app.")
            st.stop()
        else:
            st.error("setup.sh file not found. Please make sure all required files are in place.")
            st.stop()
    except subprocess.SubprocessError as e:
        st.error(f"Failed to install dependencies: {str(e)}")
        st.stop()

# Configure logger for the app
logger = get_logger("NLPInsightHub")

# ========== IMPROVED TEXT PROCESSING HELPER FUNCTIONS ==========

def improve_summary_text(text):
    """
    Improve text before summarization by focusing on important parts and removing noise.
    """
    # Remove multiple newlines and whitespace
    text = re.sub(r'\n\s*\n', '\n\n', text)
    
    # For long texts, sample from beginning, middle, and end (these usually have important info)
    if len(text) > 5000:
        first_part = text[:2000]
        middle_part = text[len(text)//2 - 1000:len(text)//2 + 1000]
        last_part = text[-2000:]
        text = first_part + "\n\n...\n\n" + middle_part + "\n\n...\n\n" + last_part
    
    return text

def enhance_sentiment_prompt(text):
    """
    Enhance the prompt for sentiment analysis to get better results.
    """
    # Create a more directive prompt for better sentiment analysis
    enhanced_prompt = f"""Analyze the sentiment in this text. 
Classify it as Positive, Negative, or Neutral.
Be decisive in your classification.
Text: {text}
Sentiment classification:"""
    
    return enhanced_prompt

def clean_summary_output(summary):
    """
    Clean up the summary output to make it more coherent.
    """
    # Remove any "Summary:" prefix that might appear in the output
    summary = re.sub(r'^(Summary:?\s*)', '', summary, flags=re.IGNORECASE)
    
    # Fix sentence spacing issues (e.g., "end.This" -> "end. This")
    summary = re.sub(r'\.([A-Z])', r'. \1', summary)
    
    # Remove duplicate sentences that might appear
    sentences = re.split(r'(?<=[.!?])\s+', summary)
    unique_sentences = []
    seen = set()
    
    for sentence in sentences:
        normalized = sentence.lower().strip()
        if normalized not in seen and len(normalized) > 10:
            seen.add(normalized)
            unique_sentences.append(sentence)
    
    # Join unique sentences back together
    improved_summary = ' '.join(unique_sentences)
    
    return improved_summary

def format_improved_summary(summary):
    """
    Format the summary with better styling.
    """
    formatted_summary = f"""## Text Summary

{summary}

*This summary was generated by AI and captures the key points from the text.*
"""
    return formatted_summary

def parse_sentiment_result(sentiment_result):
    """
    Parse sentiment results to handle different output formats (string vs dict).
    """
    if isinstance(sentiment_result, dict):
        # Handle dictionary output (new format)
        if 'sentiment' in sentiment_result:
            sentiment = sentiment_result['sentiment'].lower()
        elif 'scores' in sentiment_result:
            # Get the highest scoring sentiment
            scores = sentiment_result['scores']
            sentiment = max(scores.items(), key=lambda x: x[1])[0].lower()
        else:
            # Default fallback
            sentiment = "neutral"
    else:
        # Handle string output (old format)
        sentiment_text = str(sentiment_result).lower()
        
        if "positive" in sentiment_text:
            sentiment = "positive"
        elif "negative" in sentiment_text:
            sentiment = "negative"
        else:
            sentiment = "neutral"
    
    return sentiment

def format_improved_sentiment(sentiment_result):
    """
    Format sentiment analysis with better styling.
    """
    # Parse the sentiment
    sentiment = parse_sentiment_result(sentiment_result)
    
    # Determine emoji and color
    if sentiment == "positive":
        emoji = "üòÉ"
        sentiment_text = "Positive"
        color = "green"
    elif sentiment == "negative":
        emoji = "üòû"
        sentiment_text = "Negative"
        color = "red"
    else:
        emoji = "üòê"
        sentiment_text = "Neutral"
        color = "gray"
    
    formatted_text = f"""## Sentiment Analysis

**Overall sentiment:** **{sentiment_text}** {emoji}

*Note: This is an automated sentiment analysis that evaluates the emotional tone of the text.*
"""
    
    # Return a structure compatible with the visualization system
    return {
        "text": formatted_text,
        "raw_sentiment": sentiment,
        "sentiment": sentiment_text,
        "emoji": emoji
    }

def improve_qa_answer(answer):
    """
    Improve Q&A answers for better clarity.
    """
    # Remove any "Answer:" prefix that might appear in the output
    answer = re.sub(r'^(Answer:?\s*)', '', answer, flags=re.IGNORECASE)
    
    # Format the answer
    formatted_answer = f"""### Answer

{answer}

*Note: This answer is generated based on the provided text and may not be comprehensive.*
"""
    
    return formatted_answer

# ========== ENHANCED PROCESSING FUNCTION ==========

@st.cache_data
def process_text(text, model, tasks):
    """
    Process text with the selected model and return results for all tasks.
    We still rely on your pipeline.inference methods, 
    but we do some local pre- and post-processing.
    """
    results = {}
    
    # 1) Clean text
    clean_text = pre_processing.clean_text(text)
    
    # 2) Summarization
    if "Summarization" in tasks:
        try:
            summary_text = improve_summary_text(clean_text)
            summary = inference.get_summary(summary_text, model=model)
            improved_summary = clean_summary_output(summary)
            results["Summary"] = format_improved_summary(improved_summary)
            logger.info(f"Summarization completed with {model}")
        except Exception as e:
            logger.error(f"Summarization failed: {str(e)}")
            results["Summary"] = f"Error generating summary: {str(e)}"
    
    # 3) Sentiment
    if "Sentiment Analysis" in tasks:
        try:
            # We create a better prompt locally (though it's not strictly used by the old pipeline logic)
            sentiment_prompt = enhance_sentiment_prompt(clean_text)
            
            # Get the sentiment from inference
            sentiment = inference.get_sentiment(clean_text, model=model)
            
            # Format
            formatted_sentiment = format_improved_sentiment(sentiment)
            results["Sentiment Analysis"] = {
                "text": formatted_sentiment["text"],
                "raw_sentiment": formatted_sentiment["raw_sentiment"],
                "data": sentiment  # Keep original data for chart
            }
            logger.info(f"Sentiment analysis completed with {model}")
        except Exception as e:
            logger.error(f"Sentiment analysis failed: {str(e)}")
            results["Sentiment Analysis"] = {"text": f"Error analyzing sentiment: {str(e)}"}
    
    # 4) Keywords
    if "Keyword Extraction" in tasks:
        try:
            keywords = inference.get_keywords(clean_text, model=model)
            results["Keyword Extraction"] = {
                "text": post_processing.format_keywords(keywords),
                "data": keywords  # For visualizations
            }
        except Exception as e:
            logger.error(f"Keyword extraction failed: {str(e)}")
            results["Keyword Extraction"] = {"text": f"Error extracting keywords: {str(e)}"}
    
    return clean_text, results

def main():
    st.set_page_config(
        page_title="NLP Insight Hub",
        page_icon="üìä",
        layout="wide",
        initial_sidebar_state="expanded",
    )
    
    st.title("NLP Insight Hub")
    st.write("### An Industry-Level AI-Powered NLP Pipeline for Business Insights")
    
    # Session state
    if 'processed' not in st.session_state:
        st.session_state.processed = False
    if 'clean_text' not in st.session_state:
        st.session_state.clean_text = ""
    if 'results' not in st.session_state:
        st.session_state.results = {}
    if 'raw_text' not in st.session_state:
        st.session_state.raw_text = ""
    
    # ========== SIDEBAR: MODEL CHOICE & OPENAI KEY ==========

    st.sidebar.header("Configuration")

    # 1) Let user optionally enter an OpenAI API key
    #    If they pick "OpenAI GPT" below, we'll set this key on the model
    user_api_key = st.sidebar.text_input(
        "OpenAI API key (optional)",
        type="password",
        help="Enter your OpenAI API key if you select 'OpenAI GPT' as your model."
    )

    # 2) Model selection
    model_options = {
        "Llama": "Meta's powerful large language model",
        "Falcon": "TII's efficient open-source LLM",
        "Mistral": "Lightweight and high-performance model",
        "DeepSeek": "Advanced model for complex language tasks",
        "OpenAI GPT": "GPT-based chunked approach (requires API key)"
    }
    model_choice = st.sidebar.selectbox(
        "Select Model", 
        list(model_options.keys()),
        help="Choose the AI model that will process your text"
    )
    st.sidebar.caption(model_options[model_choice])

    # 3) Task selection
    task_options = {
        "Summarization": "Generate concise summaries of your text",
        "Sentiment Analysis": "Determine the emotional tone of the text",
        "Keyword Extraction": "Identify important topics and terms",
        "Q&A": "Ask questions about the content"
    }
    task_choices = st.sidebar.multiselect(
        "Select Tasks",
        list(task_options.keys()),
        default=["Summarization", "Sentiment Analysis"],
        help="Choose which analyses to perform on your text"
    )
    
    # 4) Advanced Settings
    with st.sidebar.expander("Advanced Settings"):
        summarization_length = st.slider(
            "Summary Length", 
            min_value=1, 
            max_value=5, 
            value=3,
            help="Controls the length of generated summaries (1=very brief, 5=detailed)"
        )
        visualization_enabled = st.checkbox(
            "Enable Visualizations", 
            value=True,
            help="Show charts and visualizations for analysis results"
        )
    
    # ========== INPUT SECTION ==========

    st.sidebar.write("Upload a text file or paste text below:")
    tab1, tab2 = st.tabs(["üìÑ Upload File", "‚úèÔ∏è Enter Text"])
    
    with tab1:
        uploaded_file = st.file_uploader("Upload your text file", type=["txt", "pdf", "docx"])
    
    with tab2:
        text_input = st.text_area("Paste text here:", height=200)
    
    # ========== PROCESS BUTTON ==========

    col1, col2 = st.columns([1, 4])
    with col1:
        process_button = st.button("Process Text", type="primary")
    with col2:
        if process_button:
            st.session_state.start_time = time.time()
    
    # ========== MAIN PROCESSING LOGIC ==========

    if process_button and (uploaded_file or text_input):
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            # Step 1: read input
            status_text.text("Reading input...")
            progress_bar.progress(10)
            
            if uploaded_file:
                file_extension = Path(uploaded_file.name).suffix
                if file_extension == '.txt':
                    raw_text = data_ingestion.read_file(uploaded_file)
                elif file_extension == '.pdf':
                    raw_text = data_ingestion.read_pdf(uploaded_file)
                elif file_extension == '.docx':
                    raw_text = data_ingestion.read_docx(uploaded_file)
                else:
                    raise ValueError("Unsupported file format.")
            else:
                if not text_input.strip():
                    st.warning("Please enter some text or upload a file.")
                    st.stop()
                raw_text = text_input

            st.session_state.raw_text = raw_text

            # Step 2: set the OpenAI API key if user chose "OpenAI GPT"
            if model_choice == "OpenAI GPT":
                if not user_api_key.strip():
                    st.error("You selected 'OpenAI GPT', but no API key was provided.")
                    st.stop()
                else:
                    # We call inference.get_model_instance(...) here just to set the key
                    model_instance = inference.get_model_instance("OpenAI GPT")
                    inference.set_openai_api_key(model_instance, user_api_key)
            
            status_text.text("Processing text...")
            progress_bar.progress(30)
            
            # Step 3: process the text with chosen tasks
            st.session_state.clean_text, st.session_state.results = process_text(
                raw_text, 
                model_choice, 
                task_choices
            )
            
            progress_bar.progress(90)
            status_text.text("Finalizing results...")
            
            st.session_state.processed = True
            progress_bar.progress(100)
            status_text.text("Processing complete!")
            
            # Show timing
            processing_time = time.time() - st.session_state.start_time
            st.success(f"‚úÖ Text processed successfully in {processing_time:.2f} seconds")
            
            time.sleep(2)
            progress_bar.empty()
            status_text.empty()
            
            st.rerun()

        except Exception as ex:
            progress_bar.empty()
            status_text.empty()
            st.error("An error occurred while processing your text.")
            st.error(f"Error details: {str(ex)}")
            logger.exception("Error in NLP processing", exc_info=ex)
            
            # Provide troubleshooting
            st.info(
                "Troubleshooting tips:\n"
                "1. Check if the text format is compatible.\n"
                "2. Try with a smaller text sample.\n"
                "3. Restart the application."
            )
    
    # ========== DISPLAY RESULTS ==========

    if st.session_state.processed:
        with st.expander("Original and Cleaned Text", expanded=False):
            tabs = st.tabs(["Original", "Cleaned"])
            with tabs[0]:
                # Show file name if used
                if 'uploaded_file' in locals() and uploaded_file:
                    st.write(f"File: {uploaded_file.name}")
                st.write(st.session_state.raw_text)
            with tabs[1]:
                st.write(st.session_state.clean_text)
                
        # Display results
        if st.session_state.results:
            st.subheader("Analysis Results")
            
            # Create tabs for Summarization, Sentiment Analysis, etc. (except Q&A)
            non_qa_tasks = [task for task in st.session_state.results.keys() if task != "Q&A"]
            result_tabs = st.tabs(non_qa_tasks)
            
            for i, (key, value) in enumerate([(k, v) for k, v in st.session_state.results.items() if k != "Q&A"]):
                with result_tabs[i]:
                    # Summaries
                    if key == "Summary":
                        st.markdown(value)

                    # Sentiment
                    elif key == "Sentiment Analysis" and isinstance(value, dict):
                        col1, col2 = st.columns([3, 2])
                        with col1:
                            if "text" in value and isinstance(value["text"], str):
                                st.markdown(value["text"])
                            else:
                                # fallback
                                raw_sentiment = value.get("raw_sentiment", "").strip().lower()
                                st.markdown("## Sentiment Analysis")
                                if "positive" in raw_sentiment:
                                    st.markdown("**Overall sentiment: Positive üòÉ**")
                                elif "negative" in raw_sentiment:
                                    st.markdown("**Overall sentiment: Negative üòû**")
                                else:
                                    st.markdown("**Overall sentiment: Neutral üòê**")
                                st.markdown("*Note: This is an automated sentiment analysis.*")
                        
                        with col2:
                            if visualization_enabled and "data" in value:
                                # 'data' is the raw sentiment dict or str
                                sentiment_chart = create_sentiment_chart(value["data"])
                                st.plotly_chart(sentiment_chart, use_container_width=True)

                    # Keywords
                    elif key == "Keyword Extraction" and "data" in value:
                        col1, col2 = st.columns([2, 3])
                        with col1:
                            if "text" in value and isinstance(value["text"], str):
                                st.markdown(value["text"])
                            else:
                                st.markdown("## Key Topics & Concepts\nKeywords extracted from the text:")
                        with col2:
                            if visualization_enabled and "data" in value:
                                keyword_cloud = create_keyword_cloud(value["data"])
                                st.plotly_chart(keyword_cloud, use_container_width=True)

                    else:
                        # Fallback for other
                        if isinstance(value, dict) and "text" in value:
                            st.markdown(value["text"])
                        else:
                            st.markdown(str(value))

            # Q&A 
            if "Q&A" in task_choices:
                st.subheader("Ask Questions About Your Text")
                question = st.text_input("Enter your question about the text:")
                ask_button = st.button("Ask Question")
                
                if question and ask_button:
                    with st.spinner("Processing your question..."):
                        try:
                            answer = inference.get_qa(st.session_state.clean_text, question, model=model_choice)
                            formatted_answer = improve_qa_answer(answer)
                            st.markdown("### Answer")
                            st.markdown(formatted_answer)
                            
                            # Save Q&A to history
                            if "Q&A History" not in st.session_state:
                                st.session_state["Q&A History"] = []
                            st.session_state["Q&A History"].append({
                                "question": question,
                                "answer": formatted_answer
                            })
                            logger.info("Q&A processing completed.")
                        except Exception as e:
                            logger.error(f"Q&A processing failed: {str(e)}")
                            st.error(f"Error processing question: {str(e)}")
                
                if "Q&A History" in st.session_state and st.session_state["Q&A History"]:
                    with st.expander("Q&A History", expanded=False):
                        for i, qa in enumerate(st.session_state["Q&A History"]):
                            st.markdown(f"**Q{i+1}: {qa['question']}**")
                            st.markdown(qa['answer'])
                            st.divider()
        
        # Export
        with st.expander("Export Results", expanded=False):
            export_format = st.selectbox("Select export format:", ["PDF", "JSON", "CSV", "TXT"])
            if st.button("Export Results"):
                st.info("Export functionality would generate a downloadable file with the results.")
                # Placeholder for actual exporting logic

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        st.error(f"Application error: {str(e)}")
        # Create a log file on error for easier debugging
        logging.basicConfig(filename='app_error.log', level=logging.ERROR)
        logging.error("Unhandled exception", exc_info=True)
